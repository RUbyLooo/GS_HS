#!/usr/bin/env python

# Copyright 2024 The HuggingFace Inc. team. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from collections import deque

import torch
from torch import nn


def populate_queues(
    queues: dict[str, deque], batch: dict[str, torch.Tensor], exclude_keys: list[str] | None = None
):
    """
    ðŸ‘‰ å°†å½“å‰ batch çš„è¾“å…¥å¼ é‡æ·»åŠ åˆ°ä¸€ä¸ªæ»‘åŠ¨çª—å£é˜Ÿåˆ—(deque)ä¸­, ç”¨äºŽæž„å»ºæ—¶é—´åºåˆ—è¾“å…¥, å¦‚ stateã€imagesã€language_tokens ç­‰ï¼Œä¾›æ¨¡åž‹é¢„æµ‹æ—¶ä½¿ç”¨
    Args:
        å‚æ•°å	                ç±»åž‹	                    ä½œç”¨
        queues	               dict[str, deque]	          æ¯ä¸ª key (ä¾‹å¦‚ state) å¯¹åº”ä¸€ä¸ªæœ‰é•¿åº¦é™åˆ¶çš„ deque (åŒç«¯é˜Ÿåˆ—)
        batch	               dict[str, torch.Tensor]	  å½“å‰æ—¶é—´æ­¥çš„è§‚æµ‹ batch (ä¾‹å¦‚ {"state": tensor(...), "images": ...})
        exclude_keys	       list[str]	              None
    """
    if exclude_keys is None:
        exclude_keys = []

    # step 1 : éåŽ†å½“å‰è¾“å…¥çš„ batch çš„æ‰€æœ‰ keys
    """
    (1) éåŽ†æ‰€æœ‰é”® (å¦‚ "state", "observation.image", "language_tokens")
    (2) å¯¹æ¯ä¸ªè§‚æµ‹é”®åˆ¤æ–­æ˜¯å¦éœ€è¦åŠ å…¥å¯¹åº”çš„é˜Ÿåˆ—
    """
    for key in batch:
        # Ignore keys not in the queues already (leaving the responsibility to the caller to make sure the
        # queues have the keys they want).
        """
        å¦‚æžœè¿™ä¸ª key :
            ä¸åœ¨ queues é‡Œ  :     å°±ä¸ç®¡ï¼ˆæ¯”å¦‚ queues åªå­˜æƒ³è¦çš„å­—æ®µï¼‰
            è¢«æ˜¾å¼æŽ’é™¤      :      ä¹Ÿä¸å¤„ç†ï¼ˆå¦‚ "action" æ˜¯æ¨¡åž‹è¾“å‡ºï¼Œä¸éœ€è¦åšæ»‘åŠ¨çª—å£ï¼‰
        """
        if key not in queues or key in exclude_keys:
            continue
        if len(queues[key]) != queues[key].maxlen:
            # initialize by copying the first observation several times until the queue is full
            while len(queues[key]) != queues[key].maxlen:
                queues[key].append(batch[key])
        else:
            # add latest observation to the queue
            queues[key].append(batch[key])
    return queues


def get_device_from_parameters(module: nn.Module) -> torch.device:
    """Get a module's device by checking one of its parameters.

    Note: assumes that all parameters have the same device
    """
    return next(iter(module.parameters())).device


def get_dtype_from_parameters(module: nn.Module) -> torch.dtype:
    """Get a module's parameter dtype by checking one of its parameters.

    Note: assumes that all parameters have the same dtype.
    """
    return next(iter(module.parameters())).dtype


def get_output_shape(module: nn.Module, input_shape: tuple) -> tuple:
    """
    Calculates the output shape of a PyTorch module given an input shape.

    Args:
        module (nn.Module): a PyTorch module
        input_shape (tuple): A tuple representing the input shape, e.g., (batch_size, channels, height, width)

    Returns:
        tuple: The output shape of the module.
    """
    dummy_input = torch.zeros(size=input_shape)
    with torch.inference_mode():
        output = module(dummy_input)
    return tuple(output.shape)
